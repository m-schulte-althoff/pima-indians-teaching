{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fd1fb8",
   "metadata": {},
   "source": [
    "# Coding Block 1 - Random Forests (and XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39695e0",
   "metadata": {},
   "source": [
    "### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b0c94e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-20T20:03:00.442022Z",
     "iopub.status.busy": "2021-09-20T20:03:00.441258Z",
     "iopub.status.idle": "2021-09-20T20:03:01.852024Z",
     "shell.execute_reply": "2021-09-20T20:03:01.851352Z",
     "shell.execute_reply.started": "2021-09-20T19:54:12.026788Z"
    },
    "papermill": {
     "duration": 1.435807,
     "end_time": "2021-09-20T20:03:01.852223",
     "exception": false,
     "start_time": "2021-09-20T20:03:00.416416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n...\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaae9e8",
   "metadata": {},
   "source": [
    "### Read the dataset \n",
    "You can also compare processed and non-processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1775d95",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-20T20:03:01.895944Z",
     "iopub.status.busy": "2021-09-20T20:03:01.895175Z",
     "iopub.status.idle": "2021-09-20T20:03:05.794695Z",
     "shell.execute_reply": "2021-09-20T20:03:05.795244Z",
     "shell.execute_reply.started": "2021-09-20T19:54:12.050571Z"
    },
    "papermill": {
     "duration": 3.924865,
     "end_time": "2021-09-20T20:03:05.795452",
     "exception": false,
     "start_time": "2021-09-20T20:03:01.870587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "diab=pd.read_csv('diabetes.csv')\n",
    "diab_cleaned=pd.read_csv('diabetes_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5937d7",
   "metadata": {},
   "source": [
    "### Split the data and train a Random Forest model\n",
    "### Evaluate the prediction models using a classification report\n",
    "### Print the feature importances of the random forest\n",
    "### Extra: Also train a XGBoost model and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878256be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgb\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load both datasets\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets = {\n",
    "    \"Original Dataset\": diab,\n",
    "    \"Cleaned Dataset\": diab_cleaned\n",
    "}\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Analysis for {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Split features and target\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    y = dataset.iloc[:, -1]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # (i) Train a Random Forest model\n",
    "    print(\"\\n--- Random Forest Model ---\")\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # (ii) Evaluate with classification report\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    print(\"\\nClassification Report for Random Forest:\")\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "    \n",
    "    # (iii) Print feature importances\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importances for Random Forest:\")\n",
    "    print(feature_importances)\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Random Forest Feature Importances - {dataset_name}')\n",
    "    plt.gca().invert_yaxis()  # Display the highest importance at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # (iv) Train XGBoost model\n",
    "    print(\"\\n--- XGBoost Model ---\")\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate XGBoost\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    print(\"\\nClassification Report for XGBoost:\")\n",
    "    print(classification_report(y_test, y_pred_xgb))\n",
    "    \n",
    "    # XGBoost feature importances\n",
    "    xgb_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': xgb_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importances for XGBoost:\")\n",
    "    print(xgb_importances)\n",
    "    \n",
    "    # Plot XGBoost feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(xgb_importances['Feature'], xgb_importances['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'XGBoost Feature Importances - {dataset_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare the models\n",
    "    print(\"\\n--- Model Comparison ---\")\n",
    "    print(f\"Random Forest Accuracy: {rf_model.score(X_test, y_test):.4f}\")\n",
    "    print(f\"XGBoost Accuracy: {xgb_model.score(X_test, y_test):.4f}\")\n",
    "    \n",
    "    # Check if there are differences in the predictions\n",
    "    disagreements = np.sum(y_pred_rf != y_pred_xgb)\n",
    "    print(f\"Number of disagreements between models: {disagreements} out of {len(y_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d03466",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pimaIndianDataAutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.933279,
   "end_time": "2021-09-20T20:03:41.801824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-20T20:02:51.868545",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
